sch["embeddings.word_embeddings"].sync(mode="fwd_pre", sync_op_or_fn=slapo.op.embed_fwd_hook)
sch["embeddings.word_embeddings"].sync(mode="fwd_post", sync_op_or_fn=slapo.op.embed_bwd_hook)
subsch["self.query"].shard(["weight", "bias"], axis=0)
subsch["self.key"].shard(["weight", "bias"], axis=0)
subsch["self.value"].shard(["weight", "bias"], axis=0)
subsch.sync(mode="bwd_post", sync_op_or_fn="all_reduce")
subsch["self.output.dense"].shard("weight", axis=1)
subsch["self.output.dense"].sync("fwd_post", sync_op_or_fn="all_reduce")
subsch["intermediate.dense"].shard(["weight", "bias"], axis=0)
subsch["intermediate.dense"].sync("bwd_post", sync_op_or_fn="all_reduce")
subsch["output.dense"].shard("weight", axis=1)
subsch["output.dense"].sync("fwd_post", sync_op_or_fn="all_reduce")
subsch["attention.output.dense"].decompose()
trace_attention()
subgraphs = sch.find(scaled_dot_product)
sch.replace(EfficientAttention(), subgraphs)
subgraph = sch.find(lambda x, bias: F.gelu(bias + x))
sch.fuse(subgraph, compiler="TorchInductor", name="BiasGeLU")
sch[path.replace("N", str(idx))].checkpoint(order_args_fn=order_args_fn)

shard_embedding()
shard_attention()
shard_mlp()
subsch["attention.output.dense"].decompose()
trace_attention()
subgraphs = sch.find(scaled_dot_product)
sch.replace(EfficientAttention(), subgraphs)
subgraph = sch.find(lambda x, bias: F.gelu(bias + x))
sch.fuse(subgraph, compiler="TorchInductor", name="BiasGeLU")
sch[path.replace("N", str(idx))].checkpoint(order_args_fn=order_args_fn)

sch["embeddings.word_embeddings"].sync(mode="fwd_pre", sync_op_or_fn=slapo.op.embed_fwd_hook)
sch["embeddings.word_embeddings"].sync(mode="fwd_post", sync_op_or_fn=slapo.op.embed_bwd_hook)
subsch["self.query|key|value"].shard(["weight", "bias"], axis=0)
subsch.sync(mode="bwd_post", sync_op_or_fn="all_reduce")
subsch["self.output.dense"].shard("weight", axis=1)
subsch["self.output.dense"].sync("fwd_post", sync_op_or_fn="all_reduce")
subsch["intermediate.dense"].shard(["weight", "bias"], axis=0)
subsch["intermediate.dense"].sync("bwd_post", sync_op_or_fn="all_reduce")
subsch["output.dense"].shard("weight", axis=1)
subsch["output.dense"].sync("fwd_post", sync_op_or_fn="all_reduce")
subsch["attention.output.dense"].decompose()
trace_attention()
subgraphs = sch.find(scaled_dot_product)
sch.replace(EfficientAttention(), subgraphs)
subgraph = sch.find(lambda x, bias: F.gelu(bias + x))
sch.fuse(subgraph, compiler="TorchInductor", name="BiasGeLU")
sch[path.replace("N", str(idx))].checkpoint(order_args_fn=order_args_fn)